# AMSDN: Adaptive Multi-Scale Defense Network

A research-grade PyTorch implementation of a unified framework for defending against patch and sparse adversarial attacks.

## ğŸ¯ Overview

AMSDN combines multiple defense mechanisms in a single, end-to-end trainable architecture:

1. **Multi-Scale Feature Extraction** (ConvNeXt-Tiny + FPN)
2. **Adaptive Attention** (Spatial + Channel + Multi-Scale Pyramid)
3. **Selective Purification** (Feature-space denoising)
4. **Prediction Consistency Verification**
5. **Self-Supervised Robustness Training** (SSRT)
6. **Randomized Smoothing Certification**

## ğŸ“Š Architecture

```
Input Image (3Ã—32Ã—32)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: ConvNeXt-Tiny + FPN        â”‚
â”‚ Output: Multi-scale features        â”‚
â”‚ [P2, P3, P4, P5] @ 256 channels     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Adaptive Attention         â”‚
â”‚ â€¢ Spatial Attention                 â”‚
â”‚ â€¢ Channel Attention                 â”‚
â”‚ â€¢ Multi-Scale Pyramid Attention     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: Selective Purification     â”‚
â”‚ â€¢ Anomaly Detection                 â”‚
â”‚ â€¢ Feature Denoising                 â”‚
â”‚ â€¢ Selective Fusion                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 4: Prediction Consistency     â”‚
â”‚ (Optional, expensive)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Head                 â”‚
â”‚ Output: Logits (10 classes)         â”‚
â”‚         Anomaly Score               â”‚
â”‚         Detection Decision          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8+
# CUDA-capable GPU (recommended)

pip install -r requirements.txt
```

### Training Pipeline

```bash
# 1. Self-Supervised Pretraining (Optional, ~1 hour)
python training/pretrain_ssrt.py

# 2. Adversarial Training (~2 hours)
python training/adversarial_train.py

# 3. Multi-Attack Fine-tuning (~30 minutes)
python training/finetune_attacks.py

# 4. Evaluation (~20 minutes)
python evaluation/evaluate.py

# 5. Certification (~30 minutes, use small sample size)
python evaluation/certification.py
```

### Google Colab

Open `notebooks/AMSDN_Colab.ipynb` in Google Colab for a complete interactive tutorial.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/AMSDN/blob/main/notebooks/AMSDN_Colab.ipynb)

## ğŸ“ Repository Structure

```
AMSDN/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cifar10.py                 # CIFAR-10 data loading
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â””â”€â”€ convnext_fpn.py        # ConvNeXt + FPN
â”‚   â”œâ”€â”€ attention/
â”‚   â”‚   â””â”€â”€ adaptive_attention.py  # Multi-scale attention
â”‚   â”œâ”€â”€ purification/
â”‚   â”‚   â””â”€â”€ selective_purifier.py  # Adversarial purification
â”‚   â””â”€â”€ amsdn.py                   # Main AMSDN model
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ pretrain_ssrt.py           # Self-supervised pretraining
â”‚   â”œâ”€â”€ adversarial_train.py       # Adversarial training
â”‚   â””â”€â”€ finetune_attacks.py        # Multi-attack fine-tuning
â”‚
â”œâ”€â”€ attacks/
â”‚   â”œâ”€â”€ patch_attacks.py           # Patch attacks (AdvPatch, BPDA)
â”‚   â””â”€â”€ pixel_attacks.py           # Sparse pixel attacks
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluate.py                # Comprehensive evaluation
â”‚   â””â”€â”€ certification.py           # Randomized smoothing
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.py                 # Visualization & utilities
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AMSDN_Colab.ipynb          # Interactive Colab notebook
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”¬ Implemented Attacks

- **PGD** (Projected Gradient Descent): Îµ=8/255, 16/255
- **C&W** (Carlini-Wagner): L2 attack
- **Patch Attacks**: Localized perturbations (4Ã—4, 8Ã—8 pixels)
- **Pixel Attacks**: Sparse perturbations (5, 10 pixels)
- **Adaptive BPDA**: Gradient obfuscation circumvention

## ğŸ“ˆ Expected Results (CIFAR-10)

After full training (~3-4 hours on T4 GPU):

| Metric | Value |
|--------|-------|
| Clean Accuracy | ~85-90% |
| PGD-8 Robust Accuracy | ~60-70% |
| Patch-4 Robust Accuracy | ~65-75% |
| Pixel-5 Robust Accuracy | ~70-80% |
| Detection Rate | ~75-85% |
| Certified Accuracy (r=0.25) | ~50-60% |

*Note: Results depend on training hyperparameters and random initialization.*

## ğŸ› ï¸ Customization

### Change Dataset

```python
# In data/cifar10.py, replace CIFAR10 with your dataset
# Modify image size in models accordingly
```

### Modify Architecture

```python
# models/amsdn.py
model = AMSDN(
    num_classes=100,              # Change number of classes
    pretrained=True,              # Use pretrained backbone
    purification_threshold=0.5,   # Detection threshold
    consistency_samples=5         # Verification samples
)
```

### Attack Strength

```python
# training/adversarial_train.py
attack = PGDAttack(
    epsilon=16/255,    # Increase perturbation budget
    alpha=2/255,
    num_steps=20
)
```

## ğŸ“Š Monitoring Training

```bash
# Launch TensorBoard
tensorboard --logdir=checkpoints/
```

## ğŸ§ª Testing Individual Components

```python
# Test backbone
python models/backbone/convnext_fpn.py

# Test attention
python models/attention/adaptive_attention.py

# Test purification
python models/purification/selective_purifier.py

# Test full model
python models/amsdn.py
```

## âš™ï¸ Configuration

### Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | T4 (16GB) | A100 (40GB) |
| RAM | 12GB | 32GB |
| Storage | 5GB | 10GB |

### Training Time

| Stage | Time (T4) | Time (A100) |
|-------|-----------|-------------|
| SSRT Pretraining | ~1 hour | ~20 minutes |
| Adversarial Training | ~2 hours | ~40 minutes |
| Fine-tuning | ~30 minutes | ~10 minutes |
| Evaluation | ~20 minutes | ~5 minutes |
| Certification | ~30 minutes | ~10 minutes |

## ğŸ› Troubleshooting

### Out of Memory (OOM)

```python
# Reduce batch size in training scripts
batch_size = 64  # or 32
```

### Slow Training

```python
# Reduce number of epochs for demo
num_epochs = 10  # instead of 100
```

### ImportError

```bash
# Ensure you're in the AMSDN root directory
cd AMSDN/
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

## ğŸ“ Citation

If you use this code for research, please cite:

```bibtex
@misc{amsdn2024,
  title={AMSDN: Adaptive Multi-Scale Defense Network},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/YOUR_USERNAME/AMSDN}}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Open a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- ConvNeXt architecture from [timm](https://github.com/rwightman/pytorch-image-models)
- Inspired by adversarial defense research from Cohen et al., Brown et al., and others
- Built with PyTorch

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact: your.email@example.com

---

**Note:** This is a research implementation. For production use, additional testing and optimization are required.

## ğŸ“ Related Work

- **Randomized Smoothing:** Cohen et al., "Certified Adversarial Robustness via Randomized Smoothing" (ICML 2019)
- **Adversarial Patch:** Brown et al., "Adversarial Patch" (NIPS 2017 Workshop)
- **PGD Attack:** Madry et al., "Towards Deep Learning Models Resistant to Adversarial Attacks" (ICLR 2018)
- **FPN:** Lin et al., "Feature Pyramid Networks for Object Detection" (CVPR 2017)
- **ConvNeXt:** Liu et al., "A ConvNet for the 2020s" (CVPR 2022)

## âš ï¸ Limitations

1. **Computational Cost:** Randomized smoothing certification is expensive (~10-100x slower than inference)
2. **Trade-offs:** Improved robustness may reduce clean accuracy
3. **Dataset:** Currently tested only on CIFAR-10; ImageNet support requires modifications
4. **Adaptive Attacks:** Defense may be vulnerable to more sophisticated adaptive attacks
5. **Hyperparameter Sensitivity:** Performance depends on careful tuning

## ğŸ”® Future Work

- [ ] ImageNet support
- [ ] Multi-GPU training
- [ ] More attack types (FGSM, DeepFool, etc.)
- [ ] Adversarial training with stronger attacks
- [ ] Model compression for deployment
- [ ] Uncertainty quantification
- [ ] Real-world evaluation on physical adversarial examples

---

**Status:** âœ… Fully implemented and tested on CIFAR-10

**Last Updated:** December 2024